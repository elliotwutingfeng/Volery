name: scraper

on:
    workflow_dispatch:
    schedule:
        - cron: "*/60 * * * *" # runs every hour

jobs:
    scrape_metadata:
        runs-on: ubuntu-latest
        steps:
            - name: checkout repo content
              uses: actions/checkout@v3

            - name: setup python
              uses: actions/setup-python@v4
              with:
                  python-version: "3.10"

            - name: install python packages
              run: |
                  python -m pip install --upgrade pip
                  pip install -r requirements.txt

            - name: fetch arch official repositories and AUR metadata and upload to database
              environment: Volery
              env:
                  NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
                  SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
              run: python database/cronjobs/fetch_repositories.py
